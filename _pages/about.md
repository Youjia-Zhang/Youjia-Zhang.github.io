---
permalink: /
title: ""
redirect_from: 
  - /about/
  - /about.html
---

I am a third year Ph.D. student at SKKU(Sungkyunkwan University), South Korea, advised by [Prof. Sungeun Hong](https://www.csehong.com/) in the Artificial and Medial Lab [AIM Lab](https://aim.skku.edu/home). My recently research interests include Multimodal Learning, Audio-Visual Recognition, Parameter-Efficient Model Tuning and Test-Time Adaptation. 


## 🔥 News
- *2025.04*: 🎉🎉 One paper is accepted to CVPR 2025 (Highlight).
- *2025.01*: 🎉🎉 One paper is accepted to Pattern Recognition (Q1, JCR: Top 6.9%).
- *2023.06*: 🎉🎉 One paper is accepted to ICMR 2023 (Oral). 
- *2022.12*: 🎉🎉 One paper is accepted to ACCV 2022 (Oral). 

## 📝 Selected Publications 
- ### Question-Aware Gaussian Experts for Audio-Visual Question Answering
  Hongyeob Kim*, Inyoung Jung*, Dayoon Suh, **Youjia Zhang**, Sangmin Lee and Sungeun Hong   
 <span style="color:MediumBlue">**CVPR 2025 [Highlight]**</span>  [[Project page]](https://aim-skku.github.io/QA-TIGER/)
- ### Memory-Efficient Cross-Modal Attention for RGB-X Segmentation and Crowd Counting
  **Youjia Zhang**, Soyun Choi, and Sungeun Hong   
 <span style="color:MediumBlue">**Pattern Recognition 2025[Q1]**</span>  [[DOI]](https://aim.skku.edu/publication/international-journal)
- ### Intra-inter modal attention blocks for RGB-D semantic segmentation
  Soyun Choi, **Youjia Zhan**g and Sungeun Hong
 <span style="color:MediumBlue">**ICMR 2023 [Oral]**</span>  [[Project page]](https://aim.skku.edu/publication/international-conference/ima_icmr23)
- ### Spatio-channel attention blocks for cross-modal crowd counting
  **Youjia Zhang**, Soyun Choi, and Sungeun Hong   
 <span style="color:MediumBlue">**ACCV 2022 [Oral]**</span>  [Project page]  [[Project page]](https://aim.skku.edu/publication/international-conference/csca_accv22)


## 📂 Projects
- ### RGB-X Path Networks for Multi-modal Multi-task Learning  (2023.03 ~ 2026.02)  
  - Funded by National Research Foundation of Korea (NRF)  
  - Develop path networks for RGB-X data (e.g., depth, thermal, tactile, text) to enable efficient multi-modal fusion and knowledge transfer across tasks and environments, thereby supporting generalization and adaptability in complex real-world settings
- ### Visuo-Tactile Perception for Human-Like Manipulation of Deformable Objects with Dynamic Center of Mass (2021.09 ~ 2023.08)
  - Funded by Samsung Research Funding & Incubation Center for Future Technology
  - Develop core technologies for stable grasping and manipulation of soft, deformable objects through “visual-tactile fusion” and “visual-tactile perception” for robots to manipulate objects at the human level.

## 💡 Patents
  - Spatio-channel attention blocks for cross-modal crowd counting (Registration number C-2022-055027)

## 📚 Academic Activities
<div style="font-size: 88%; line-height: 1.4;">
  
### Reviewer
- ACM International Conference on Multimedia (ACM MM)  
- Neural Information Processing Systems (NeurIPS)  

### Teaching Assistant  
- Introduction to Deep Learning, Spring 2025  
- Advanced Computer Vision, Fall 2024  
- Computer Vision, Fall 2021  
</div>

 

## 🎓 Education
<ul style="font-size: 88%">
  <li>2024 – Present: Ph.D. Student, Department of Immersive Media Engineering, Sungkyunkwan University, advised by <a href="https://www.csehong.com/">Prof. Sungeun Hong</a></li>
  <li>2021 – 2024: Ph.D. Student, Department of Information and Communication Engineering, Inha University, advised by <a href="https://www.csehong.com/">Prof. Sungeun Hong</a></li>
  <li>2018 – 2021: M.S., School of Computer Science and Technology, CQUPT, advised by <a href="https://faculty.cqupt.edu.cn/zhangx/zh_CN/index.htm">Prof. Xu Zhang</a></li>
  <li>2014 – 2018: B.S., School of Mathematics and Statistics, Chongqing University of Posts and Telecommunications (CQUPT)</li>
</ul>

